{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWveem512v+l2+QME5Kq7q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Install required libraries\n","!pip install -q pandas numpy bokeh pathway\n","\n","# Imports\n","import pandas as pd\n","import numpy as np\n","from bokeh.plotting import figure, output_notebook, show\n","from bokeh.models import ColumnDataSource\n","from bokeh.layouts import gridplot\n","from math import radians, cos, sin, asin, sqrt\n","import pathway as pw\n","import time\n","import threading\n","\n","# Enable Bokeh for Colab\n","output_notebook()\n","\n","# ============================\n","# LOAD + PREPROCESS DATASET\n","# ============================\n","df = pd.read_csv(\"dataset.csv\")\n","df.columns = df.columns.str.lower().str.strip()\n","column_mapping = {\n","    'id': 'record_id',\n","    'systemcodenumber': 'lot_id',\n","    'capacity': 'capacity',\n","    'latitude': 'latitude',\n","    'longitude': 'longitude',\n","    'occupancy': 'occupancy',\n","    'vehicletype': 'vehicle_type',\n","    'trafficconditionnearby': 'traffic_level',\n","    'queuelength': 'queue_length',\n","    'isspecialday': 'is_special_day',\n","    'lastupdateddate': 'date',\n","    'lastupdatedtime': 'time'\n","}\n","df = df.rename(columns=column_mapping)\n","df['timestamp'] = pd.to_datetime(df['date'] + ' ' + df['time'], dayfirst=True, errors='coerce')\n","df = df.drop(columns=['date', 'time', 'record_id'])\n","df = df.sort_values('timestamp')\n","\n","# Clean + Normalize\n","df['occupancy'] = pd.to_numeric(df['occupancy'], errors='coerce').fillna(0).astype(int)\n","df['capacity'] = pd.to_numeric(df['capacity'], errors='coerce').fillna(1).astype(int)\n","df['queue_length'] = pd.to_numeric(df['queue_length'], errors='coerce').fillna(0).astype(int)\n","df['is_special_day'] = pd.to_numeric(df['is_special_day'], errors='coerce').fillna(0).astype(int)\n","df['traffic_level'] = df['traffic_level'].astype(str).str.lower()\n","df['vehicle_type'] = df['vehicle_type'].astype(str).str.lower()\n","\n","# Feature Engineering\n","vehicle_weights = {'car': 1, 'bike': 0.6, 'truck': 1.5}\n","df['occupancy_rate'] = df['occupancy'] / df['capacity'].replace(0, 1)\n","df['vehicle_weight'] = df['vehicle_type'].map(vehicle_weights).fillna(1)\n","df['normalized_traffic'] = df['traffic_level'].map({'low': 0.2, 'average': 0.5, 'high': 0.8}).fillna(0.5)\n","\n","# ============================\n","# PRICING MODELS\n","# ============================\n","\n","def model_1_linear(df, alpha=5):\n","    df['price_model1'] = 10 + alpha * df['occupancy_rate']\n","    return df['price_model1'].clip(lower=5, upper=20)\n","\n","def compute_demand(row):\n","    return (\n","        1 * row['occupancy_rate'] +\n","        0.5 * row['queue_length'] -\n","        0.7 * row['normalized_traffic'] +\n","        1.0 * row['is_special_day'] +\n","        1.2 * row['vehicle_weight']\n","    )\n","\n","def model_2_demand(df):\n","    df['demand'] = df.apply(compute_demand, axis=1)\n","    df['normalized_demand'] = (df['demand'] - df['demand'].mean()) / df['demand'].std()\n","    df['price_model2'] = 10 * (1 + 0.2 * df['normalized_demand'])\n","    return df['price_model2'].clip(lower=5, upper=20)\n","\n","def vectorized_haversine(lat1, lon1, lat2, lon2):\n","    R = 6371\n","    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n","    dlat = lat2 - lat1\n","    dlon = lon2 - lon1\n","    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n","    return R * 2 * np.arcsin(np.sqrt(a))\n","\n","def model_3_competition(df):\n","    df['price_model3'] = df['price_model2'].copy()\n","    for ts in df['timestamp'].unique():\n","        ts_df = df[df['timestamp'] == ts]\n","        if len(ts_df) <= 1: continue\n","        lat, lon = ts_df['latitude'].values, ts_df['longitude'].values\n","        dist_matrix = np.zeros((len(ts_df), len(ts_df)))\n","        for i in range(len(ts_df)):\n","            dist_matrix[i] = vectorized_haversine(lat[i], lon[i], lat, lon)\n","        mask = (dist_matrix < 1.0) & (dist_matrix > 0)\n","        for i, idx in enumerate(ts_df.index):\n","            neighbors = np.where(mask[i])[0]\n","            if len(neighbors) > 0:\n","                avg_price = ts_df.iloc[neighbors]['price_model2'].mean()\n","                if ts_df.iloc[i]['occupancy_rate'] > 0.95 and avg_price < ts_df.iloc[i]['price_model2']:\n","                    df.at[idx, 'price_model3'] = max(5, ts_df.iloc[i]['price_model2'] - 1)\n","                elif avg_price > ts_df.iloc[i]['price_model2']:\n","                    df.at[idx, 'price_model3'] = min(20, ts_df.iloc[i]['price_model2'] + 1)\n","    return df['price_model3'].clip(lower=5, upper=20)\n","\n","df['price_model1'] = model_1_linear(df)\n","df['price_model2'] = model_2_demand(df)\n","df['price_model3'] = model_3_competition(df)\n","\n","# ============================\n","# REROUTING FUNCTION\n","# ============================\n","def haversine(lat1, lon1, lat2, lon2):\n","    R = 6371\n","    dlat = radians(lat2 - lat1)\n","    dlon = radians(lon2 - lon1)\n","    a = sin(dlat/2)**2 + cos(radians(lat1)) * cos(radians(lat2)) * sin(dlon/2)**2\n","    return R * 2 * asin(sqrt(a))\n","\n","def suggest_rerouting(df, lot_id, timestamp):\n","    lot_df = df[(df['lot_id'] == lot_id) & (df['timestamp'] == pd.to_datetime(timestamp))]\n","    if lot_df.empty or lot_df.iloc[0]['occupancy_rate'] <= 0.95:\n","        return None\n","    row = lot_df.iloc[0]\n","    nearby = df[(df['timestamp'] == row['timestamp']) & (df['lot_id'] != lot_id)].copy()\n","    nearby['distance'] = nearby.apply(\n","        lambda r: haversine(row['latitude'], row['longitude'], r['latitude'], r['longitude']),\n","        axis=1\n","    )\n","    alternatives = nearby[(nearby['distance'] < 1.0) & (nearby['occupancy_rate'] < 0.8)]\n","    if not alternatives.empty:\n","        best = alternatives.sort_values('price_model3').iloc[0]\n","        return f\"Reroute to {best['lot_id']} (Price: ${best['price_model3']:.2f}, Distance: {best['distance']:.2f} km)\"\n","    return None\n","\n","# ============================\n","# SAVE CLEANED DATA\n","# ============================\n","df.to_csv('modified_dataset.csv', index=False)\n","\n","# ============================\n","# PATHWAY STREAMING SETUP\n","# ============================\n","class ParkingSchema(pw.Schema):\n","    timestamp: str\n","    lot_id: str\n","    occupancy: int\n","    capacity: int\n","    queue_length: int\n","    traffic_level: str\n","    is_special_day: int\n","    vehicle_type: str\n","    latitude: float\n","    longitude: float\n","    occupancy_rate: float\n","    vehicle_weight: float\n","    normalized_traffic: float\n","    price_model1: float\n","    price_model2: float\n","    price_model3: float\n","\n","def simulate_streaming(input_csv, output_csv, delay_seconds=0.01):\n","    df = pd.read_csv(input_csv)\n","    df['timestamp'] = df['timestamp'].astype(str)\n","    with open(output_csv, 'w') as f:\n","        f.write(','.join(df.columns) + '\\n')\n","    for _, row in df.iterrows():\n","        with open(output_csv, 'a') as f:\n","            f.write(','.join(map(str, row.values)) + '\\n')\n","        time.sleep(delay_seconds)\n","\n","# Start streaming\n","threading.Thread(target=simulate_streaming, args=('modified_dataset.csv', 'streaming_dataset.csv')).start()\n","\n","# Run Pathway pipeline\n","table = pw.io.csv.read('streaming_dataset.csv', schema=ParkingSchema, mode='streaming')\n","avg_prices = table.groupby(table.lot_id).reduce(\n","    lot_id=table.lot_id,\n","    avg_price_model1=pw.reducers.avg(table.price_model1),\n","    avg_price_model2=pw.reducers.avg(table.price_model2),\n","    avg_price_model3=pw.reducers.avg(table.price_model3)\n",")\n","pw.io.csv.write(avg_prices, 'output_prices.csv')\n","pw.run(monitoring_level=pw.MonitoringLevel.ALL)\n","\n","# ============================\n","# VISUALIZATION\n","# ============================\n","def plot_comparison(df, lot_id):\n","    df_lot = df[df['lot_id'] == lot_id]\n","    source = ColumnDataSource(df_lot)\n","    p = figure(title=f\"Pricing Models - {lot_id}\", x_axis_type=\"datetime\", width=400, height=400)\n","    p.line('timestamp', 'price_model1', source=source, color=\"blue\", legend_label=\"Model 1\")\n","    p.line('timestamp', 'price_model2', source=source, color=\"green\", legend_label=\"Model 2\")\n","    p.line('timestamp', 'price_model3', source=source, color=\"red\", legend_label=\"Model 3\")\n","    p.legend.location = \"top_left\"\n","    return p\n","\n","def plot_competitor_comparison(df, lot_id, timestamp):\n","    lot_df = df[(df['lot_id'] == lot_id) & (df['timestamp'] == pd.to_datetime(timestamp))]\n","    if lot_df.empty: return None\n","    row = lot_df.iloc[0]\n","    nearby = df[(df['timestamp'] == row['timestamp']) & (df['lot_id'] != lot_id)].copy()\n","    nearby['distance'] = nearby.apply(lambda r: haversine(row['latitude'], row['longitude'], r['latitude'], r['longitude']), axis=1)\n","    competitors = nearby[nearby['distance'] < 1.0]\n","    if competitors.empty: return None\n","    data = {'lot_id': [lot_id] + competitors['lot_id'].tolist(), 'price': [row['price_model3']] + competitors['price_model2'].tolist()}\n","    p = figure(x_range=data['lot_id'], title=f\"Competitor Prices - {lot_id} @ {timestamp}\", width=400, height=400)\n","    p.vbar(x='lot_id', top='price', source=ColumnDataSource(pd.DataFrame(data)), width=0.4, color=\"purple\")\n","    return p\n","\n","# Show plots\n","p1 = plot_comparison(df, 'BHMBCCMKT01')\n","p2 = plot_competitor_comparison(df, 'BHMBCCMKT01', '2016-12-18 08:30:00')\n","show(gridplot([[p1, p2]]))\n","\n","# ============================\n","# REAL-TIME PREDICTIONS\n","# ============================\n","print(\"ðŸš— Real-Time Pricing Predictions:\\n\")\n","for _, row in df.iterrows():\n","    lot_id, timestamp = row['lot_id'], row['timestamp']\n","    print(f\"[{timestamp}] Lot {lot_id} | M1=${row['price_model1']:.2f} M2=${row['price_model2']:.2f} M3=${row['price_model3']:.2f}\")\n","    reroute = suggest_rerouting(df, lot_id, timestamp)\n","    if reroute: print(f\"ðŸ” {reroute}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"SEvYuDtJAH-s","executionInfo":{"status":"error","timestamp":1751699417447,"user_tz":-330,"elapsed":6811,"user":{"displayName":"Prashun Mishra","userId":"10588103468958010343"}},"outputId":"7d80c9a9-04a5-4dd1-fef1-9564988ae3db"},"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'dataset.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2-3343178853.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# LOAD + PREPROCESS DATASET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# ============================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m column_mapping = {\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset.csv'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-XgWd36F8sfQ"},"execution_count":null,"outputs":[]}]}